{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043dde0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "import cvxopt\n",
    "import patsy\n",
    "import os\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "pl.Config.set_float_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae93134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the oj dataset\n",
    "os.chdir('/Users/noaht/OneDrive/Desktop/ECON_487')\n",
    "data_oj = pl.read_csv('oj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46379650",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_oj = data_oj.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ed0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a log_price column\n",
    "data_oj = data_oj.with_columns(\n",
    "    pl.col('price').log().alias('log_price')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e8dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a row id\n",
    "data_oj = data_oj.with_row_index('row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d461d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag stuff\n",
    "# table to join\n",
    "df1 = (\n",
    "    data_oj\n",
    "    .select(['store', 'brand', 'week', 'log_price'])\n",
    "    .sort(['store', 'brand', 'week'])\n",
    "    .with_columns(\n",
    "        (pl.col('week')+1).alias('week'),\n",
    "    )\n",
    ")\n",
    "# dataframe with lagged log price\n",
    "df2 = (\n",
    "    data_oj\n",
    "    .join(df1, on=['brand','store','week'], how='left')\n",
    ")\n",
    "df2 = df2.sort([\"store\", \"brand\", \"week\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4d3ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refining stuff\n",
    "lag_price_data = (\n",
    "    df2\n",
    "    .rename({'log_price_right': 'lag_price'})\n",
    "    # taking out the null values\n",
    "    .filter(pl.col(\"lag_price\").is_not_null())\n",
    "    # changing the minute maid alias so there's less syntax problems in the future \n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"brand\") == \"minute.maid\")\n",
    "        .then(pl.lit(\"minute_maid\"))\n",
    "        .otherwise(pl.col(\"brand\"))\n",
    "        .alias(\"brand\")  \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "098e5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_lpd = lag_price_data.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ac3bd",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf17f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=487)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35d0eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "absurd_formula = 'logmove ~ (log_price + lag_price + +feat + AGE60 + EDUC + ETHNIC + C(brand) +' \\\n",
    "          'INCOME + HHLARGE + WORKWOM + HVAL150 + SSTRDIST + SSTRVOL + ' \\\n",
    "          'CPDIST5 + CPWVOL5)**2-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267fac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0.0010; Avg MSE = 0.39\n",
      "Alpha = 0.0018; Avg MSE = 0.39\n",
      "Alpha = 0.0032; Avg MSE = 0.40\n",
      "Alpha = 0.0056; Avg MSE = 0.42\n",
      "Alpha = 0.0100; Avg MSE = 0.44\n",
      "\n",
      "Best alpha: 0.0010\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-3, -2, 5)  \n",
    "\n",
    "# alpha --> penalty \n",
    "alpha_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    mse = []\n",
    "    \n",
    "    for train_i, test_i in folds.split(lag_price_data):\n",
    "        train_data = lag_price_data[train_i].to_pandas()\n",
    "        test_data = lag_price_data[test_i].to_pandas()\n",
    "        \n",
    "        y_train, X_train = patsy.dmatrices(absurd_formula, data=train_data, return_type='dataframe')\n",
    "        y_test, X_test = patsy.dmatrices(absurd_formula, data=test_data, return_type='dataframe')\n",
    "        \n",
    "        model = sm.OLS(y_train, X_train).fit_regularized(method = 'elastic_net', L1_wt=1, alpha=alpha)\n",
    "        \n",
    "        y_hat = model.predict(X_test)\n",
    "        \n",
    "        model_mse = mean_squared_error(y_test, y_hat)\n",
    "        mse.append(model_mse)\n",
    "    \n",
    "    avg_mse = np.mean(mse)\n",
    "    \n",
    "    alpha_results.append({\n",
    "        'alpha': alpha,\n",
    "        'avg_mse': avg_mse})\n",
    "    print(f\"Alpha = {alpha:.4f}; Avg MSE = {avg_mse:.2f}\")\n",
    "\n",
    "results_df = pd.DataFrame(alpha_results)\n",
    "best_alpha = results_df.loc[results_df['avg_mse'].idxmin(), 'alpha']\n",
    "print(f\"\\nBest alpha: {best_alpha:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4415e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "convert the absurd_formula variables into a numerical matrix the regression model can use\n",
    "    this formula does different things\n",
    "    creates dummy variables for the categorical variables\n",
    "\"\"\"\n",
    "y, X = patsy.dmatrices(absurd_formula, data=pd_lpd, return_type='dataframe')\n",
    "\n",
    "# LASSO Regression \n",
    "best_model = sm.OLS(y, X).fit_regularized(method = 'elastic_net', L1_wt=1, alpha=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38db16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "return the non-zero parameters after LASSO is performed\n",
    "    this is using the absurd formula which probably wouldn't be done in practice\n",
    "    the absurd formula is just used to illustrate a point\n",
    "\"\"\" \n",
    "# create a series mapping coefficient names to thier values\n",
    "coef = pd.Series(best_model.params, index=X.columns)\n",
    "\n",
    "# find the non-zero coefficients --> survived LASSO\n",
    "nonzero_cols = np.abs(coef) != 0 \n",
    "\n",
    "# maka a polars dataframe of the features that survived\n",
    "nonzero_features = pl.DataFrame({\n",
    "    'feature': pl.Series(X.columns[nonzero_cols])\n",
    "})\n",
    "\n",
    "with pl.Config(tbl_rows=200):\n",
    "    print(nonzero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49bc2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit the model only using the the variables that LASSO selects\n",
    "refit_lasso = sm.OLS(y, X).fit_regularized(method = 'elastic_net', L1_wt=1, alpha=.001, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0a38d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_price                           -1.617964\n",
      "log_price:C(brand)[T.minute_maid]    0.247364\n",
      "log_price:C(brand)[T.tropicana]      0.859430\n",
      "log_price:lag_price                 -1.466326\n",
      "log_price:feat                      -0.628343\n",
      "log_price:AGE60                      0.000000\n",
      "log_price:EDUC                       0.000000\n",
      "log_price:ETHNIC                     0.000000\n",
      "log_price:INCOME                    -0.025758\n",
      "log_price:HHLARGE                    0.000000\n",
      "log_price:WORKWOM                    0.000000\n",
      "log_price:HVAL150                    0.319606\n",
      "log_price:SSTRDIST                  -0.021176\n",
      "log_price:SSTRVOL                    0.000000\n",
      "log_price:CPDIST5                    0.036387\n",
      "log_price:CPWVOL5                    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# show all the variables that affect log_price\n",
    "log_price_coefs = coef[coef.index.str.contains(\"log_price\", case=False)]\n",
    "print(log_price_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6f716",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide data --> use for elasticities\n",
    "wide_data = (\n",
    "    lag_price_data\n",
    "    .select([\"store\", \"week\", \"brand\", \"log_price\", 'lag_price',\"feat\"])\n",
    "    .unpivot(index=[\"store\", \"week\", \"brand\", \"feat\"], on=[\"log_price\", 'lag_price', 'feat'])\n",
    "    # naming stuff\n",
    "    .with_columns(\n",
    "        pl.concat_str([pl.col(\"variable\"), pl.lit(\"_\"), pl.col(\"brand\")]).alias(\"name\")\n",
    "    )\n",
    "    .drop(\"brand\")\n",
    "    .pivot(index=[\"store\", \"week\"], on=\"name\", values=\"value\")\n",
    ")\n",
    "\n",
    "# table we're going to use for cross price elasticities\n",
    "cross_price_data = (\n",
    "    data_oj\n",
    "    .select(['store', 'week', 'logmove', 'brand'])\n",
    "    .join(wide_data, how='left', on=['store', 'week'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbd695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>q_var</th><th>log_price_dominicks</th><th>log_price_minute_maid</th><th>log_price_tropicana</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;dominicks&quot;</td><td>-3.56</td><td>1.25</td><td>0.06</td></tr><tr><td>&quot;minute_maid&quot;</td><td>0.91</td><td>-3.86</td><td>1.18</td></tr><tr><td>&quot;tropicana&quot;</td><td>0.27</td><td>0.43</td><td>-2.87</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "┌─────────────┬─────────────────────┬───────────────────────┬─────────────────────┐\n",
       "│ q_var       ┆ log_price_dominicks ┆ log_price_minute_maid ┆ log_price_tropicana │\n",
       "│ ---         ┆ ---                 ┆ ---                   ┆ ---                 │\n",
       "│ str         ┆ f64                 ┆ f64                   ┆ f64                 │\n",
       "╞═════════════╪═════════════════════╪═══════════════════════╪═════════════════════╡\n",
       "│ dominicks   ┆ -3.56               ┆ 1.25                  ┆ 0.06                │\n",
       "│ minute_maid ┆ 0.91                ┆ -3.86                 ┆ 1.18                │\n",
       "│ tropicana   ┆ 0.27                ┆ 0.43                  ┆ -2.87               │\n",
       "└─────────────┴─────────────────────┴───────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert polars dataframe to pandas\n",
    "cp_pd = cross_price_data.to_pandas()\n",
    "\n",
    "def fit_brand(group):\n",
    "    fit = smf.ols(\n",
    "        \"logmove ~ log_price_dominicks + log_price_minute_maid + log_price_tropicana\",\n",
    "        data=group\n",
    "    ).fit()\n",
    "    return {\n",
    "        # get the brand name\n",
    "        \"q_var\": group[\"brand\"].iloc[0],\n",
    "        # extract cross price effects (coefficients)\n",
    "        \"log_price_dominicks\": fit.params[\"log_price_dominicks\"],\n",
    "        \"log_price_minute_maid\": fit.params[\"log_price_minute_maid\"],\n",
    "        \"log_price_tropicana\": fit.params[\"log_price_tropicana\"]\n",
    "    }\n",
    "# loop through each brand --> list of dictionaries\n",
    "results = [fit_brand(g) for _, g in cp_pd.groupby(\"brand\")]\n",
    "# turn into clean table\n",
    "out = pl.DataFrame(results).sort(\"q_var\")\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa54bd5c",
   "metadata": {},
   "source": [
    "### interact all price variables with feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dbf9914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>q_var</th><th>log_price_dominicks</th><th>log_price_minute_maid</th><th>log_price_tropicana</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;dominicks&quot;</td><td>-2.87</td><td>0.81</td><td>-0.26</td></tr><tr><td>&quot;minute_maid&quot;</td><td>0.56</td><td>-2.35</td><td>0.33</td></tr><tr><td>&quot;tropicana&quot;</td><td>0.15</td><td>0.28</td><td>-2.17</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "┌─────────────┬─────────────────────┬───────────────────────┬─────────────────────┐\n",
       "│ q_var       ┆ log_price_dominicks ┆ log_price_minute_maid ┆ log_price_tropicana │\n",
       "│ ---         ┆ ---                 ┆ ---                   ┆ ---                 │\n",
       "│ str         ┆ f64                 ┆ f64                   ┆ f64                 │\n",
       "╞═════════════╪═════════════════════╪═══════════════════════╪═════════════════════╡\n",
       "│ dominicks   ┆ -2.87               ┆ 0.81                  ┆ -0.26               │\n",
       "│ minute_maid ┆ 0.56                ┆ -2.35                 ┆ 0.33                │\n",
       "│ tropicana   ┆ 0.15                ┆ 0.28                  ┆ -2.17               │\n",
       "└─────────────┴─────────────────────┴───────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def price_feat_reg(brand_var: str, cross_price_data: pl.DataFrame) -> pl.DataFrame:\n",
    "    \n",
    "    sub = cross_price_data.filter(pl.col(\"brand\") == brand_var).to_pandas()\n",
    "    \n",
    "    feat_col = f\"feat_{brand_var}\"\n",
    "    formula = (\n",
    "        \"logmove ~ (log_price_dominicks + log_price_minute_maid + log_price_tropicana) \"\n",
    "        f\"* {feat_col}\"\n",
    "    )\n",
    "    fit = smf.ols(formula, data=sub).fit()\n",
    "\n",
    "    coefs = fit.params\n",
    "    return pl.DataFrame({\n",
    "        \"q_var\": [brand_var],\n",
    "        \"log_price_dominicks\": [coefs['log_price_dominicks']],\n",
    "        \"log_price_minute_maid\": [coefs[\"log_price_minute_maid\"]],\n",
    "        \"log_price_tropicana\": [coefs[\"log_price_tropicana\"]],\n",
    "    })\n",
    "\n",
    "\n",
    "brand_list = data_oj.select(\"brand\").unique().to_series().to_list()\n",
    "rows = [price_feat_reg(b, cross_price_data) for b in brand_list]\n",
    "out = pl.concat(rows, how=\"vertical\").sort(\"q_var\")\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b5834",
   "metadata": {},
   "source": [
    "it's interesting that the cross price elasticity between dominicks and tropicana is negative. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
